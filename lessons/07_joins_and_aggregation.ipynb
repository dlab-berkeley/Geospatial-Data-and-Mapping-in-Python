{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute and Spatial Joins\n",
    "\n",
    "Now that we understand the logic of spatial relationship queries, let's take a look at another fundamental spatial operation that relies on them.\n",
    "\n",
    "This operation, called a **spatial join**, is the process by which we can leverage the spatial relationships between distinct datasets to merge their information into a new, synthetic dataset.\n",
    "\n",
    "This operation can be thought as the spatial equivalent of an **attribute join**, in which multiple tabular datasets can be merged by aligning matching values in a common column that they both contain. If you've done data wrangling in Python with pandas, you've probably performed an attribute join at some point!\n",
    "\n",
    "Thus, we'll start by developing an understanding of this operation first!\n",
    "\n",
    "<!-- \n",
    "- Expected time to complete\n",
    "    - Lecture + Questions: 45 minutes\n",
    "    - Exercises: 20 minutes\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input and Preparation\n",
    "\n",
    "Let's read in a table of data from the US Census' 5-year American Community Survey (ACS5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the ACS5 data for CA into a pandas DataFrame.\n",
    "# Note: We force the FIPS_11_digit to be read in as a string to preserve any leading zeroes.\n",
    "acs5_df = pd.read_csv(\"../data/census/ACS5yr/census_variables_CA.csv\", dtype={'FIPS_11_digit': str})\n",
    "acs5_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brief summary of the data**:\n",
    "\n",
    "Below is a table of the variables in this table. They were combined from \n",
    "different ACS 5 year tables.\n",
    "\n",
    "A few things to note:\n",
    "- Variables that start with `c_` are counts.\n",
    "- Variables that start with `med_` are medians.\n",
    "- Variables that end in `_moe` are margin of error estimates.\n",
    "- Variables that start with `_p` are proportions calcuated from the counts divided by the table denominator (the total count for whom that variable was assessed).\n",
    "\n",
    "\n",
    "| Variable        | Description                                     |\n",
    "|-----------------|-------------------------------------------------|\n",
    "|`c_race`         |Total population                                 \n",
    "|`c_white`        |Total white non-Latinx\n",
    "| `c_black`       | Total black and African American non-Latinx\n",
    "| `c_asian`       | Total Asian non-Latinx\n",
    "| `c_latinx`      | Total Latinx\n",
    "| `state_fips`    | State level FIPS code\n",
    "| `county_fips`   | County level FIPS code\n",
    "| `tract_fips`    |Tracts level FIPS code\n",
    "| `med_rent`      |Median rent\n",
    "| `med_hhinc`     |Median household income\n",
    "| `c_tenants`     |Total tenants\n",
    "| `c_owners`      |Total owners\n",
    "| `c_renters`     |Total renters\n",
    "| `c_movers`      |Total number of people who moved\n",
    "| `c_stay`        |Total number of people who stayed\n",
    "| `c_movelocal`   |Number of people who moved locally\n",
    "| `c_movecounty`  |Number of people who moved counties\n",
    "| `c_movestate`   | Number of people who moved states\n",
    "| `c_moveabroad`  |Number of people who moved abroad\n",
    "| `c_commute`     |Total number of commuters\n",
    "| `c_car`         | Number of commuters who use a car\n",
    "| `c_carpool`     | Number of commuters who carpool\n",
    "| `c_transit`     |Number of commuters who use public transit\n",
    "| `c_bike`        |Number of commuters who bike\n",
    "| `c_walk`        |Number of commuters who bike\n",
    "| `year`          | ACS data year\n",
    "| `FIPS_11_digit` | 11-digit FIPS code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to drop all of our `moe` columns by identifying all of those that end with `_moe`. We can do that in two steps, first by using `filter` to identify columns that contain the string `_moe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moe_cols = acs5_df.filter(like='_moe', axis=1).columns\n",
    "moe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs5_df.drop(moe_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, let's grab only the rows for year 2018 and county FIPS code 1 (Alameda County)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs5_df_ac = acs5_df[(acs5_df['year'] == 2018) & (acs5_df['county_fips'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's read in the Census tracts again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_gdf = gpd.read_file(\"zip://../data/census/Tracts/cb_2013_06_tract_500k.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the tracts within Alameda county\n",
    "tracts_gdf_ac = tracts_gdf[tracts_gdf['COUNTYFP'] == '001']\n",
    "tracts_gdf_ac.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Joins\n",
    "\n",
    "We just mapped the Census tracts. But what makes a map powerful is when you map the data associated with the locations within the map. So, let's take a stab at performing an attribute join between the GeoDataFrame of tracts, and the DataFrame of ACS data.\n",
    "\n",
    "Why do we need to do this? Let's reflect on the current DataFrames we're working with\n",
    "\n",
    "- `tracts_gdf_ac` contains polygon data in a GeoDataFrame. However, as we saw in the `head` of that dataset, there are no attributes of interest!\n",
    "- `acs5_df_ac` contains 2018 ACS data from a CSV file (`census_variables_CA.csv`), imported and read in as a pandas DataFrame. However, they have no geometries!\n",
    "\n",
    "In order to map the ACS data we need to associate it with the tracts. Let's do that now, by joining the columns from `acs5_df_ac` to the columns of `tracts_gdf_ac` using a common column as the key for matching rows. This process is called an **attribute join**. There are several ways we can go about performing this join.\n",
    "\n",
    "<img src=\"https://shanelynnwebsite-mid9n9g1q9y8tt.netdna-ssl.com/wp-content/uploads/2017/03/join-types-merge-names.jpg\">\n",
    "\n",
    "The image above gives us a nice conceptual summary of the types of joins we could run.\n",
    "\n",
    "Before we begin, let's reflect on a couple points:\n",
    "\n",
    "1. In general, why might we choose one type of join over another?\n",
    "2. In our case, do we want an inner, left, right, or outer (AKA 'full') join? \n",
    "\n",
    "> **NOTE**: You can read more about merging in `geopandas` [here](http://geopandas.org/mergingdata.html#attribute-joins).\n",
    "\n",
    "Now, let's perform the join! Let's take a look at the common column in both our DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_gdf_ac['GEOID'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs5_df_ac['FIPS_11_digit'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that they are **not named the same thing**. \n",
    "        \n",
    "That's okay! We just need to know that they contain the same information.\n",
    "\n",
    "Also note that they are **not in the same order**. \n",
    "        \n",
    "That's not only okay... that's the point! If they were in the same order already then we could just join them side by side, without having Python find and line up the matching rows from each!\n",
    "\n",
    "Let's do a `left` join to keep all of the Census tracts in Alameda County and only the ACS data for those tracts.\n",
    "\n",
    "> **NOTE**: To figure out how to do this we could always take a peek at the documentation by calling\n",
    "`?tracts_gdf_ac.merge`, or `help(tracts_gdf_ac)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join keeps all tracts and the ACS data for those tracts\n",
    "tracts_acs_gdf_ac = tracts_gdf_ac.merge(acs5_df_ac,\n",
    "                                        left_on='GEOID',\n",
    "                                        right_on='FIPS_11_digit',\n",
    "                                        how='left')\n",
    "tracts_acs_gdf_ac.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we have all the variables we have in our dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tracts_acs_gdf_ac.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence check: in this case, how many rows and columns should we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rows and columns in the Alameda County Census tract GeoDataFrame: {tracts_gdf_ac.shape}\")\n",
    "print(f\"Row and columns in the ACS5 2018 data: {acs5_df_ac.shape}\")\n",
    "print(f\"Rows and columns in the Alameda County Census tract GeoDataFrame joined to the ACS data: {tracts_acs_gdf_ac.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save out our merged data so we can use it in the final notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_acs_gdf_ac.to_file('../data/outdata/tracts_acs_gdf_ac.json', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 1: Choropleth Map\n",
    "\n",
    "We can now make choropleth maps using our attribute-joined GeoDataFrame. Go ahead and pick one variable to color the map, then map it. You can go back to lesson 5 if you need a refresher on how to make this!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Joins\n",
    "\n",
    "Great! We've wrapped our heads around the concept of an attribute join. Now, let's extend that concept to its spatially explicit equivalent: the **spatial join**!\n",
    "\n",
    "To start, we'll read in some other data: The Alameda County schools data. Then, we'll work with that data and our `tracts_acs_gdf_ac` data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import schools data\n",
    "schools_df = pd.read_csv('../data/alco_schools.csv')\n",
    "# Convert to GeoDataFrame\n",
    "schools_gdf = gpd.GeoDataFrame(schools_df, \n",
    "                               geometry=gpd.points_from_xy(schools_df.X, schools_df.Y))\n",
    "# Convert CRS\n",
    "schools_gdf.crs = \"epsg:4326\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we have to transform the schools to match the `tracts_acs_gdf_ac` CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'schools_gdf CRS: {schools_gdf.crs}')\n",
    "print(f'tracts_acs_gdf_ac CRS: {tracts_acs_gdf_ac.crs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, we do! Let's do that.\n",
    "\n",
    "Note that, we didn't even necessarily have to check whether they different. The syntax below will work in all cases, and allows us not to have to type out the EPSG code ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_gdf = schools_gdf.to_crs(tracts_acs_gdf_ac.crs)\n",
    "\n",
    "print(f'schools_gdf CRS: {schools_gdf.crs}')\n",
    "print(f'tracts_acs_gdf_ac CRS: {tracts_acs_gdf_ac.crs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to combine the datasets in an analysis. In this case, we want to get data from the Census tract within which each school is located.\n",
    "\n",
    "How can we do that? The two datasets don't share a common column to use for a join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_acs_gdf_ac.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_gdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, they do have a shared relationship by way of space! \n",
    "\n",
    "So, we'll use a spatial relationship query to figure out the Census tract that each school is in, then associate the tract's data with that school (as additional data in the school's row). This is a **spatial join**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Tract Data Associated with Each School\n",
    "\n",
    "In this case, let's say we're interested in the relationship between the median household income in a Census tract (`tracts_acs_gdf_ac['med_hhinc']`) and a school's Academic Performance Index (`schools_gdf['API']`).\n",
    "\n",
    "To start, let's take a look at the distributions of our two variables of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_acs_gdf_ac.hist('med_hhinc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_gdf.hist('API')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, right! There are schools with no reported APIs (i.e. API == 0)! Let's drop those. We'll do this in the interest of pedagogy for this workshop, but it's also worth keeping in mind: what do we lose by dropping those schools? How might that impact the results of our analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_gdf_api = schools_gdf[schools_gdf['API'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_gdf_api.hist('API')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, maybe we think there ought to be some correlation between the two variables? As a first pass at this possibility, let's overlay the two datasets, coloring each one by its variable of interest. This should give us a sense of whether or not similar values co-occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = tracts_acs_gdf_ac.plot(column='med_hhinc',\n",
    "                            cmap='cividis',\n",
    "                            figsize=(18, 18),\n",
    "                            legend=True,\n",
    "                            legend_kwds={'label': \"median household income ($)\",\n",
    "                                         'orientation': \"horizontal\"})\n",
    "schools_gdf_api.plot(column='API',\n",
    "                     cmap='cividis',\n",
    "                     edgecolor='black',\n",
    "                     alpha=1,\n",
    "                     ax=ax,\n",
    "                     legend=True,\n",
    "                     legend_kwds={'label': \"API\",\n",
    "                                  'orientation': \"horizontal\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatially Joining the Schools and Census Tracts\n",
    "\n",
    "Though it's hard to say for sure, it certainly looks possible. It would be ideal to scatter the variables! But in order to do that, we need to know the median household income in each school's tract, which means we definitely need our **spatial join**!\n",
    "\n",
    "We'll first take a look at the documentation for the spatial join function, `gpd.sjoin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(gpd.sjoin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the key arguments to consider are:\n",
    "\n",
    "- The two GeoDataFrames (**`left_df`** and **`right_df`**);\n",
    "- The type of join to run (**`how`**), which can take the values `left`, `right`, or `inner`;\n",
    "- The spatial relationship query to use (**`op`**).\n",
    "\n",
    "A couple things to note:\n",
    "\n",
    "- By default, `sjoin` is an inner join. It keeps the data from both GeoDataFrames only where the locations spatially intersect.\n",
    "- By default, `sjoin` maintains the geometry of first geodataframe input to the operation. \n",
    "\n",
    "So, before we move on, let's think about how we'll conduct this analysis.\n",
    "\n",
    "1. Which GeoDataFrame are we joining onto which (i.e. which one is getting the other one's data added to it)?\n",
    "2. What happened to 'outer' as a join type?\n",
    "3. Thus, in our operation, which GeoDataFrame should be the `left_df`, which should be the `right_df`, and `how` do we want our join to run?\n",
    "\n",
    "Alright! Let's run our join!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_jointracts = gpd.sjoin(left_df=schools_gdf_api,\n",
    "                               right_df=tracts_acs_gdf_ac,\n",
    "                               how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_jointracts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 2: Confidence Checks\n",
    "\n",
    "As always, we want to perform a confidence check on our intermediate result before we rush ahead.\n",
    "\n",
    "One way to do that is to introspect the structure of the result object a bit.\n",
    "\n",
    "1. What type of object should that have given us?\n",
    "2. What should the dimensions of that object be, and why?\n",
    "3. If we wanted a visual check of our results (i.e. a plot or map), what could we do?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmed! The output of the `sjoin` operation is a GeoDataFrame (`schools_jointracts`) with:\n",
    "- A row for each school that is located inside a census tract (all of them are).\n",
    "- The **point geometry** of that school.\n",
    "- All of the attribute data columns (non-geometry columns) from both input GeoDataFrames.\n",
    "\n",
    "Let's also take a look at an overlay map of the schools on the tracts. If we color the schools categorically by their tracts IDs, then we should see that all schools within a given tract polygon are the same color.\n",
    "\n",
    "We're only going to plot a few of the schools, because we don't have enough colors on the color wheel for each unique tract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = tracts_acs_gdf_ac.plot(color='white',\n",
    "                            edgecolor='black',\n",
    "                            figsize=(18, 18))\n",
    "schools_jointracts.iloc[:16].plot(column='GEOID', ax=ax, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the Relationship between Median Household Income and API\n",
    "\n",
    "Fantastic! That looks right!\n",
    "\n",
    "Now, we can create that scatter plot we were thinking about!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(schools_jointracts.med_hhinc, schools_jointracts.API)\n",
    "ax.set_xlabel('Median Household Income (Dollars)')\n",
    "ax.set_ylabel('Academic Performance Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Just as we suspected based on our overlay map,\n",
    "there's a pretty obvious, strong, and positive correlation\n",
    "between median household income in a school's tract\n",
    "and the school's API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "\n",
    "We just saw that a spatial join in one way to leverage the spatial relationship between two datasets in order to create a new dataset,\n",
    "\n",
    "An **aggregation** is another way we can generate new data from this relationship. In this case, for each feature in one dataset we find all the features in another dataset that satisfy our chosen spatial relationship query with it (e.g. within, intersects), then aggregate them using some summary function (e.g. count, mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Aggregated School Counts\n",
    "\n",
    "Let's take this for a spin with our data. We'll count all the schools within each Census tract.\n",
    "\n",
    "Note that we've already done the first step of spatially joining the data from the aggregating features\n",
    "(the tracts) onto the data to be aggregated (our schools).\n",
    "\n",
    "The next step is to group our GeoDataFrame by Census tract, and then summarize our data by group. We do this using the DataFrame method `groupy`.\n",
    "\n",
    "To get the correct count, lets rejoin our schools on our tracts, this time keeping all schools (not just those with positive APIs, as before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_jointracts = gpd.sjoin(schools_gdf, tracts_acs_gdf_ac, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform the `groupby` operation.\n",
    "\n",
    "When aggregating by count, we'll get the counts for every column, which will be the same. So, we'll just select the `GEOID` and `Site` columns at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_countsbytract = schools_jointracts.groupby('GEOID', as_index=False).count()[['GEOID','Site']]\n",
    "print(f\"Counts, rows and columns: {schools_countsbytract.shape}\")\n",
    "print(f\"Tracts, rows and columns: {tracts_acs_gdf_ac.shape}\")\n",
    "\n",
    "# Take a look at the data\n",
    "schools_countsbytract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining Tract Polygons with School Counts\n",
    "\n",
    "The above `groupby` and `count` operations give us the counts we wanted.\n",
    "\n",
    "- We have 263 (of 361) Census tracts that contain at least one school.\n",
    "- We have the number of schools within each of those tracts.\n",
    "\n",
    "But, the output of `groupby` is a plain DataFrame, and not a GeoDataFrame.\n",
    "\n",
    "If we want a GeoDataFrame, then we have two options:\n",
    "\n",
    "1. We could join the `groupby` output to `tracts_acs_gdf_ac` by the attribute `GEOID`.\n",
    "2. We could start over, using the GeoDataFrame `dissolve` method, which we can think of as a spatial `groupby`.\n",
    "\n",
    "Since we already know how to do an attribute join, we'll do the `dissolve`!\n",
    "\n",
    "First, let's run a new spatial join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_joinschools = gpd.sjoin(left_df=schools_gdf,\n",
    "                               right_df=tracts_acs_gdf_ac,\n",
    "                               how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_joinschools.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the dissolve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_schoolcounts = tracts_joinschools[['GEOID', 'Site', 'geometry']].dissolve(by='GEOID', aggfunc='count')\n",
    "print(f\"Counts, rows and columns: {tracts_schoolcounts.shape}\")\n",
    "\n",
    "tracts_schoolcounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Let's break that down.\n",
    "\n",
    "- The `dissolve` operation requires a geometry column and a grouping column (in our case, `'GEOID'`). Any geometries within the **same group** will be dissolved if they have the same geometry or nested geometries. \n",
    " \n",
    "- The `aggfunc`, or aggregation function, of the dissolve operation will be applied to all numeric columns in the input geodataframe (unless the function is `count` in which case it will count rows).  \n",
    "\n",
    "Check out the Geopandas documentation on [dissolve](https://geopandas.org/aggregation_with_dissolve.html?highlight=dissolve) for more information.\n",
    "\n",
    "Now, let' reflect:\n",
    "\n",
    "1. Above, we selected three columns from the input GeoDataFrame to create a subset as input to the dissolve operation. Why?\n",
    "2. Why did we run a new spatial join? What would have happened if we had used the `schools_jointracts` object instead?\n",
    "3. What explains the dimensions of the new object (361, 2)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping the Spatial Join Output\n",
    "\n",
    "Because our `sjoin` plus `dissolve` pipeline outputs a GeoDataFrame, we can now easily map the school count by Census tract!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (14, 8)) \n",
    "\n",
    "# Display the output of our spatial join\n",
    "tracts_schoolcounts.plot(ax=ax,\n",
    "                         column='Site', \n",
    "                         scheme=\"user_defined\",\n",
    "                         classification_kwds={'bins': list(range(9))},\n",
    "                         cmap=\"PuRd_r\",\n",
    "                         edgecolor=\"grey\",\n",
    "                         legend=True, \n",
    "                         legend_kwds={'title': 'Number of schools'})\n",
    "schools_gdf.plot(ax=ax,\n",
    "                 color='cyan',\n",
    "                 markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Challenge 3: Aggregation\n",
    "\n",
    "What is the mean API of each Census tract?\n",
    "\n",
    "As we mentioned, the spatial aggregation workflow that we just put together above could have been used not to generate a new count variable, but also to generate any other new variable the results from calling an aggregation function on an attribute column.\n",
    "\n",
    "In this case, we want to calculate and map the mean API of the schools in each Census tract.\n",
    "\n",
    "Copy and paste code from above where useful, then tweak and/or add to that code. Do the following:\n",
    "\n",
    "1. Join the schools onto the tracts (**HINT**: make sure to decide whether or not you want to include schools with API = 0!).\n",
    "2. Dissolves that joined object by the tract IDs, giving you a new GeoDataFrame with each tract's mean API (**HINT**: because this is now a different calculation, different problems may arise and need handling!).\n",
    "3. Plot the tracts, colored by API scores (**HINT**: overlay the schools points again, visualizing them in a way that will help you visually check your results!).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
